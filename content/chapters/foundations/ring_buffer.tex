\section{Ring buffer}
\label{sec:ring-buffer}

Il \emph{ring buffer} (o \emph{circular buffer}) è una coda circolare che utilizza un array di dimensione fissa e due indici (\texttt{head} e \texttt{tail}) per tracciare le posizioni di scrittura e lettura, aggiornati in modo ciclico tramite aritmetica modulo la capacità del buffer~\cite{ringbuffer:circular}. Quando \texttt{head} raggiunge la fine dell'array, si avvolge al principio, creando una struttura ciclica che riusa la memoria della stessa allocazione senza necessità di reallocazione o spostamento di elementi. Questa proprietà è fondamentale per le applicazioni di streaming: invece di accodare elementi a una fine e deaccodarli dall'altra (con relativa necessità di shift), il ring buffer semplicemente avanza i due indici in modo circolare, mantenendo complessità $O(1)$ per enqueue e dequeue~\cite{ringbuffer:performance}.

Per ottimizzare le prestazioni su architetture multicore, gli indici \texttt{head} e \texttt{tail} sono rappresentati mediante tipi atomici, garantendo che le operazioni di lettura e incremento siano atomiche a livello CPU e visibili a tutti i core senza necessità di lock espliciti. Inoltre, la capacità del buffer è tipicamente arrotondata alla potenza di due più vicina, consentendo di sostituire l'operazione di modulo (costosa, richiedendo una divisione) con una maschera bit-a-bit (\texttt{index \& capMask}), dove \texttt{capMask = capacity - 1}. Ad esempio, se la capacità è 256 ($2^8$), \texttt{capMask} è 255 (\texttt{0xFF} in binario), e calcolare \texttt{(head + 1) \& 255} è equivalente a \texttt{(head + 1) \% 256} ma richiede solo un'operazione bitwise anziché una divisione.

Un aspetto cruciale dell'implementazione di ring buffer concorrenti è il sistematico impiego del \emph{padding di cache line}. Nelle architetture moderne x86-64, le cache line hanno tipicamente una dimensione di 64 byte. Quando la CPU accede a un dato in memoria, l'intero blocco di 64 byte contenente quel dato viene caricato nella cache locale del core. In contesti concorrenti, questo può generare un fenomeno noto come \emph{false sharing}: quando due thread accedono a variabili distinte che però risiedono nella stessa cache line, il protocollo di coerenza della cache costringe l'intera cache line a essere invalidata e ricaricata ogni volta che uno dei due thread la modifica, anche se le variabili non condividono logicamente dati~\cite{cache:falsesharing}.

In un ring buffer concorrente, dove producer (chi scrive) e consumer (chi legge) operano rispettivamente su \texttt{head} e \texttt{tail}, il false sharing comporterebbe un overhead catastrofico: ogni scrittura su \texttt{head} da parte del producer invaliderebbe la cache line contenente \texttt{tail} nei core dei consumer, e viceversa, causando centinaia di cicli di latenza aggiuntivi per ogni accesso. Separando \texttt{head} e \texttt{tail} tramite padding (ovvero inserendo campi dummy di 64 byte tra loro), si garantisce che i due indici risiedano su cache line diverse, eliminando completamente la contesa. Studi empirici hanno dimostrato che questo padding può migliorare il throughput di un ordine di grandezza in scenari di alta contesa multicore.

I ring buffer specializzati utilizzati sono:

\begin{itemize}
    \item \textbf{SPSC (Single Producer Single Consumer)}: Un singolo thread scrive, un singolo legge. Non è necessaria sincronizzazione ulteriore oltre alle barriere di memoria fornite dalle operazioni atomiche. È la variante più semplice e performante.
    
    \item \textbf{SPMC (Single Producer Multiple Consumer)}: Un singolo thread scrive, molteplici leggono. Richiede coordinamento affinché ogni dato sia consumato una sola volta, tipicamente tramite flag atomici e operazioni compare-and-swap.
    
    \item \textbf{MPSC (Multiple Producer Single Consumer)}: Molteplici thread scrivono, un singolo legge. Simmetricamente a SPMC, richiede coordinamento sulla scrittura tramite compare-and-swap per determinare quale producer ha il diritto di scrivere nella prossima posizione.
\end{itemize}

Le operazioni di enqueue (scrittura) e dequeue (lettura) sui ring buffer adottano tipicamente una \emph{strategia ibrida di backpressure}~\cite{backpressure:spinblock}: inizialmente tentano l'operazione tramite un numero limitato di tentativi (spinning), cedendo brevemente la goroutine tra un tentativo e l'altro per evitare busy-waiting puro. Se dopo la fase di spinning il buffer rimane pieno (per enqueue) o vuoto (per dequeue), il thread si blocca su una condition variable fino a quando non viene segnalato spazio disponibile o il buffer viene chiuso. Questo approccio ibrido combina l'efficienza del busy-waiting per brevi periodi di contesa con il blocco efficiente per periodi prolungati, riducendo il consumo di CPU in scenari di alta pressione.