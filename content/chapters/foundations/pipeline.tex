\section{Modello pipeline}
\label{sec:pipeline}

Nel contesto dei sistemi di elaborazione dati, una pipeline è una sequenza di stadi (stage) attraverso cui i messaggi fluiscono in modo ordinato, trasformandosi progressivamente da una rappresentazione grezza (raw data) a una forma più strutturata e significativa dal punto di vista del dominio applicativo. Ogni stage ha responsabilità ben delimitata e definita: riceve input da stage precedenti o da sorgenti esterne, applica una trasformazione specifica, e produce un output che diventa l'ingresso dello stage successivo. Questa decomposizione architettonica promuove modularità, separazione delle responsabilità, riusabilità e facilita la comprensione e il testing di ciascun componente isolatamente~\cite{pipeline:patterns}.

Dal punto di vista della concorrenza, il modello pipeline consente un notevole beneficio di throughput: ogni stage può operare in parallelo sugli elementi che riceve. Concretamente, mentre lo stage 1 elabora il messaggio N, lo stage 2 può già processare il messaggio N-1, e lo stage 3 il messaggio N-2. Questo parallelismo stadio-a-stadio incrementa significativamente il throughput complessivo del sistema rispetto a un'elaborazione sequenziale: invece di attendere che ogni messaggio attraversi tutta la catena prima di processarne uno nuovo, il sistema mantiene un ``pipelining'' attivo dove più messaggi sono elaborati contemporaneamente in stadi diversi.

Un aspetto centrale riguarda i meccanismi di collegamento tra stage, poiché devono garantire sia la sicurezza rispetto alla concorrenza (thread-safety) sia la capacità di assorbire variazioni locali di carico. In particolare, l'impiego di buffer intermedi (code) consente di mitigare la \emph{backpressure}, il fenomeno per cui uno stage più lento a valle ``rallenterebbe'' la produzione di uno stage più veloce a monte se non vi fossero buffer di accumulo. Un buffer consente temporaneamente di disaccoppiare la velocità di produzione da quella di consumo, riducendo l'impatto di variabilità di carico sulla latenza end-to-end~\cite{backpressure:reactive}. Per massimizzare le prestazioni in scenari ad alto throughput, i connettori tra stage devono essere implementati con strutture dati lock-free, come ring buffer specializzati, che sostituiscono i meccanismi tradizionali di sincronizzazione.