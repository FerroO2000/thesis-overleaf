\section{Lock-free data structures}
\label{sec:lock-free}

Le strutture dati \emph{lock-free} sono progettate per consentire l'accesso concorrente da parte di molteplici thread senza ricorrere a primitive di sincronizzazione bloccanti come mutex o semafori, affidandosi invece a operazioni atomiche e a protocolli non bloccanti basati su hardware~\cite{lockfree:survey}. In ambienti multicore, questo approccio riduce drasticamente la contesa sulle risorse, limita il context switching (scambio di contesto) tra thread, e migliora la scalabilità del sistema al crescere sia del numero di core che del carico di lavoro.

La fondazione delle strutture lock-free è l'operazione \emph{Compare-and-Swap} (CAS). Una operazione CAS è un'istruzione atomica a livello hardware che, in un'unica fase indivisibile, legge una locazione di memoria, confronta il suo valore con un valore atteso e, solo se coincidono, lo sostituisce con un nuovo valore, ritornando il risultato del confronto~\cite{cas:operations}. Formalmente: $\texttt{CAS}(\texttt{addr}, \texttt{atteso}, \texttt{nuovo})$ legge il valore in \texttt{addr}, se è uguale ad \texttt{atteso} lo sostituisce con \texttt{nuovo} e ritorna vero, altrimenti non modifica nulla e ritorna falso. Poiché l'intera operazione è atomica a livello CPU, nessun altro thread può leggere o modificare \texttt{addr} durante l'esecuzione di CAS, eliminando condizioni di race intrinsiche.

Le operazioni atomiche rappresentano una alternativa ai lock bloccanti: invece di acquisire un lock e mantenere un diritto esclusivo su una risorsa per la durata di una sezione critica, un thread modifica la risorsa tramite CAS e, se rileva che il valore è cambiato da quando l'ha letto (indicando interferenza da parte di un altro thread), ritenta l'operazione. Questo schema funziona bene quando la contesa è ridotta e i conflitti sono rari, offrendo latenza inferiore rispetto ai lock bloccanti in tali scenari~\cite{lockfree:algorithms}. La proprietà lock-free garantisce inoltre che, indipendentemente dallo scheduling dei thread, almeno un thread farà sempre progressi verso il completamento della propria operazione, anche se altri thread vengono sospesi o rallentati.