\section{OpenTelemetry}

OpenTelemetry è un framework e toolkit di osservabilità open source, nato sotto la Cloud Native Computing Foundation (CNCF), che fornisce un insieme unificato di API, SDK e strumenti per l’instrumentation, la generazione, la raccolta e l’esportazione di dati di telemetria (tracce, metriche e log) da sistemi distribuiti eterogenei~\cite{otel:what}. L’obiettivo principale di OpenTelemetry è standardizzare il modo in cui le applicazioni producono telemetria, riducendo il lock-in verso specifici vendor e permettendo di sostituire o affiancare backend diversi (ad esempio Prometheus, Jaeger, o soluzioni commerciali) senza modificare il codice applicativo. In questo senso, OpenTelemetry non è un sistema di storage o visualizzazione dei dati, bensì uno strato di instrumentazione e trasporto vendor-agnostic, concepito per diventare parte integrante dell’infrastruttura software.

La specifica OpenTelemetry definisce un modello dati comune per i tre segnali fondamentali dell’osservabilità (traces, metrics, logs), le semantiche di propagazione del contesto distribuito e il protocollo di trasporto OTLP (OpenTelemetry Protocol). A partire da tali basi comuni, vengono fornite API e SDK per molteplici linguaggi, che consentono di instrumentare manualmente il codice (creazione esplicita di span, metriche, log strutturati) oppure di sfruttare l’instrumentation automatica di librerie e framework diffusi. Un aspetto centrale del modello è la correlazione tra segnali: le log entry e le misure metriche possono essere arricchite con TraceId e SpanId, consentendo di passare in modo diretto da un log di errore alla traccia corrispondente, o di correlare un picco di latenza osservato su una metrica con il path di esecuzione che lo ha generato.

Elemento chiave dell’ecosistema è l’OpenTelemetry Collector, un container eseguibile che implementa una pipeline di elaborazione generica per la telemetria: riceve dati da molteplici sorgenti, li trasforma e li esporta verso uno o più backend~\cite{otel:collector}. L’architettura del Collector è esplicitamente pipeline-based e suddivisa in componenti: i receiver ingeriscono i dati (ad esempio via OTLP/gRPC, OTLP/HTTP, Prometheus, Jaeger), i processor applicano trasformazioni (batching, filtering, arricchimento di attributi, tail sampling), mentre gli exporter inviano i dati verso sistemi di persistenza o analisi. Questa configurazione è descritta tramite file YAML che definiscono una o più pipeline per tipo di segnale (traces, metrics, logs), in modo concettualmente analogo al modello di pipeline implementato dalla libreria Goccia: ricezione, processing e consegna come fasi separate e componibili.