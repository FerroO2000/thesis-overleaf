\subsection{Kafka}

Il \textit{Kafka stage} rappresenta un \textit{Ingress stage} progettato per consumare messaggi da topic \textit{Kafka}, integrandosi direttamente con architetture \textit{event-driven} e sistemi di \textit{streaming} dati. A differenza dei precedenti \textit{Ingress stage} (\textit{Ticker}, \textit{UDP}, \textit{TCP}), il \textit{Kafka stage} non implementa un protocollo di trasporto diretto, ma si affida a un broker centralizzato (\textit{Kafka}) per la gestione persistente e distribuita dei messaggi. Questa caratteristica lo rende ideale in scenari in cui i dati provengono da molteplici produttori asincroni, in cui è necessario garantire una semantica di consegna robusta (\textit{at-least-once}, \textit{exactly-once}), oppure in cui si desiderano costruire pipeline di elaborazione fortemente \textit{decoupled}. La libreria \textbf{Goccia} sfrutta la libreria open-source \textit{segmentio/kafka-go}, un'implementazione Go-nativa del protocollo \textit{Kafka} che evita dipendenze da librerie esterne come \textit{librdkafka}~\cite{segmentio:kafka-go,confluent:librdkafka}.

La configurazione del \textit{Kafka stage} è estremamente flessibile e riflette la complessità intrinseca del sistema \textit{Kafka}. La struct \texttt{KafkaConfig} mima la struttura di configurazione \texttt{ReaderConfig} fornita dalla dipendenza \textit{kafka-go}, così da consentire all'utente una personalizzazione completa della connessione verso i broker \textit{Kafka}~\cite{segmentio:kafka-go:readerconfig}. In questo modo è possibile controllare, tra gli altri, parametri relativi ai broker, al \textit{consumer group}, alle politiche di bilanciamento delle partizioni, ai timeout di lettura e alle strategie di backoff. Di default, lo \textit{stage} consuma i messaggi utilizzando un \textit{group id}, in modo da sfruttare la gestione automatica degli \textit{offset} offerta dal broker quando i dati vengono letti dai topic.

La logica di lettura dello \textit{stage} è volutamente semplice: il cuore dell'implementazione è un unico ciclo \texttt{for} che invoca ripetutamente il metodo \texttt{ReadMessage} del \textit{reader} \textit{kafka-go}~\cite{segmentio:kafka-go:readmessage}. Ogni chiamata restituisce un nuovo messaggio \textit{Kafka}, che viene poi trasformato in una struct \texttt{KafkaMessage} e inserito nel \textit{connector} di output dello \textit{stage}. In caso di errore, se questo è dovuto alla cancellazione del \texttt{context}, il ciclo termina in modo ordinato; negli altri casi l'errore viene registrato tramite il sottosistema di telemetria, e il ciclo procede al tentativo successivo, garantendo una maggiore robustezza in presenza di problemi transitori di rete o di broker.

Dal punto di vista dell'osservabilità, oltre alle metriche comuni a tutti gli \textit{Ingress stage} (numero di messaggi e byte ricevuti), il \textit{Kafka stage} introduce la possibilità di estrarre il contesto di \textit{tracing} direttamente dagli \textit{header} del messaggio \textit{Kafka}. A tale scopo viene utilizzata una struttura dedicata che implementa l'interfaccia \textit{TextMapPropagator} definita dallo standard \textit{OpenTelemetry}~\cite{otel:textmap:propagator}. Questo meccanismo consente di propagare i \textit{trace} tra servizi differenti, permettendo la costruzione di un sistema di \textit{tracing} distribuito in cui ogni messaggio \textit{Kafka} può trasportare il contesto di esecuzione end-to-end lungo l'intera pipeline.

<disegno screenshot trace distribuito>

