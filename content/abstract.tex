Il presente lavoro di tesi si concentra sul \textit{design} e l'implementazione di \textbf{Goccia}, una libreria ad alte prestazioni per la costruzione di \textit{data pipeline} nel linguaggio Go, progettata per contesti \textit{cloud-native} e sistemi di elaborazione dati concorrenti. La libreria nasce dall'esigenza di superare i limiti delle primitive di concorrenza native di Go (\textit{goroutine} e \textit{channel}) in scenari con requisiti stringenti di \textit{throughput} e latenza, fornendo un'infrastruttura modulare e riusabile per il \textit{processing} di flussi di dati ad alto volume. 

L'architettura di \textbf{Goccia} si fonda su due componenti essenziali: \texttt{Stage} e \texttt{Connector}. Gli \textit{stage} implementano un \textit{lifecycle} ben definito (\texttt{Init}, \texttt{Run}, \texttt{Close}) e sono categorizzati in tre gruppi principali: \texttt{Ingress Stage} (punti di ingresso dati: UDP, TCP, Kafka, eBPF, File), \texttt{Processor Stage} (trasformazioni modulari: decodifica CAN, Cannelloni, CSV, \texttt{Filter}, \texttt{Tee}, \texttt{Reorder Buffer}, \texttt{Custom}) ed \texttt{Egress Stage} (persistenza verso destinazioni esterne: QuestDB, Kafka, File, UDP/TCP). I \texttt{Connector} utilizzano \textit{ring buffer lock-free} nelle varianti SPSC (\textit{Single Producer Single Consumer}), SPMC (\textit{Single Producer Multiple Consumer}) e MPSC (\textit{Multiple Producer Single Consumer}), sostituendo i \textit{channel} nativi di Go per massimizzare il \textit{throughput}. 

L'implementazione dei \textit{ring buffer} si basa su operazioni atomiche \textit{Compare-and-Swap} (CAS) e sfrutta il \textit{padding} delle \textit{cache line} per eliminare il fenomeno del \textit{false sharing}, migliorando il \textit{throughput} in scenari di alta contesa in sistemi multicore. Le operazioni di \texttt{enqueue} e \texttt{dequeue} adottano una strategia ibrida: \textit{spinning} limitato iniziale seguito da blocco su \textit{condition variable}, combinando l'efficienza del \textit{busy-waiting} con la gestione efficiente di contese prolungate. La libreria integra un \texttt{Worker Pool} con \textit{autoscaling} adattivo e uno \texttt{Scaler} che regola dinamicamente il numero di \textit{worker} in funzione della profondità della coda di \textit{fan-out}. 

\textbf{Goccia} supporta nativamente OpenTelemetry per il tracciamento distribuito, le metriche e i \textit{log} strutturati. Il \texttt{Reorder Buffer} (ROB) implementa il metodo di Holt per il \textit{Double Exponential Smoothing}, stimando e correggendo i \textit{timestamp} di messaggi affetti da \textit{jitter} di rete. Il principale caso d'uso è il sistema di telemetria automobilistica di SquadraCorse Polito, organizzato in cinque livelli: \textit{Ingestion Layer} (acquisizione dati CAN via UDP/Cannelloni), \textit{Processing Layer} (decodifica, riordinamento), \textit{Storage Layer} (persistenza in QuestDB), \textit{Observability Layer} (OpenTelemetry Collector, Prometheus, Grafana Tempo) e \textit{Visualization Layer} (Grafana). 

I \textit{benchmark} dimostrano che i \textit{ring buffer lock-free} di \textbf{Goccia} offrono \textit{speedup} compresi tra 1.5x e 4.75x rispetto ai \textit{channel} standard di Go in scenari rappresentativi, riducendo significativamente latenza e contesa. Gli sviluppi futuri includono il supporto ai protocolli QUIC e MQTT, l'introduzione di \textit{pattern} avanzati (\textit{Request-Reply} con \textit{Futures}, \textit{Content-Based Routing}), l'integrazione con InfluxDB e il miglioramento complessivo della \textit{test coverage}.